# Accelerate Generative AI application operations with LLMOps


## Introduction

This is a 2-part workshop designed to equip participants with the knowledge and hands-on experience to efficiently deploy and evolve applications backed by Large Language Models (LLMs) on Amazon Web Services (AWS).

Part 1 kicks off with a thorough introduction to essential concepts, such as Containerization, Continuous Integration/Continuous Delivery (CI/CD) and Infrastructure as Code (IaC). Participants will engage in practical exercises aimed at deploying an example LLM-backed application onto the AWS cloud infrastructure with a CICD pipeline, gaining firsthand experience with various AWS services such as Amazon Bedrock, CodePipeline, Cloud Development Kit, etc.
 
Part 2 focuses on enhancing the application and its CICD pipeline by introducing a continuous fine-tuning stage to improve the foundation model and adding retrieval augmented generation (RAG) using Amazon Bedrock, SageMaker and OpenSearch. Through hands-on activities, participants will learn how to leverage the power and scalability of AWS services for machine learning use cases.


## Outcomes

By the end of this workshop, participants will have a good foundation for operating Generative AI applications on AWS and practical skills on:

- Working with various AWS Services: Amazon Bedrock, SageMaker, ECS, CodePipeline, etc.
- Evolving applications backed by Generative AI.
- Containerization.
- Writing Infrastructure as Code.
- Building a CICD pipeline.


## Terminology

**Generative AI** is a type of artificial intelligence capable of generating new content, data, or outputs such as text, images, videos, music, etc.

**Foundation Models** are large machine learning models that are pre-trained on vast amounts of data, often terabytes, which can be used natively or serves as the basis for various downstream natural language processing tasks, providing a robust starting point for further fine-tuning and customization to specific applications or domains.

**Large Language Models (LLMs)** are advanced artificial intelligence systems trained on vast amounts of text data, capable of understanding and generating human-like text across various tasks such as language translation, text summarization, question answering, and more.

**Machine Learning Operations (MLOps)** is the discipline of managing and automating the lifecycle of machine learning models, from development to deployment and maintenance, to ensure their efficient and reliable operation in production environments.

**Foundation Model Operations (FMOps)** takes the MLOps methodology and adds the additional skills, processes, and technologies needed to operationalize Generative AI models.

## Start the workshop

Follow the instructions to [start the workshop](.docs/00-getting-started.md).
